{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-IxNmlXULVa",
        "outputId": "b66ea5b2-73a8-424a-91a2-c7da1d2c8dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTtIy34A9JYO",
        "outputId": "73132046-9985-46b1-8ba0-224be2a594ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 2.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=ccd676dbf6923f13e4534039220f50dc73217afca1cbc0d3b0d7a7a6ab4a0d83\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c 11-785-s22-hw2p2-classification\n",
        "!kaggle competitions download -c 11-785-s22-hw2p2-verification\n",
        "\n",
        "!unzip -q 11-785-s22-hw2p2-classification.zip\n",
        "!unzip -q 11-785-s22-hw2p2-verification.zip\n",
        "\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQurdcTd9Te6",
        "outputId": "00485f6e-9064-4d3d-958e-9ec4e3fdebef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-s22-hw2p2-classification.zip to /content\n",
            "100% 2.35G/2.35G [00:36<00:00, 93.0MB/s]\n",
            "100% 2.35G/2.35G [00:36<00:00, 70.1MB/s]\n",
            "Downloading 11-785-s22-hw2p2-verification.zip to /content\n",
            " 92% 242M/263M [00:07<00:00, 39.0MB/s]\n",
            "100% 263M/263M [00:07<00:00, 36.1MB/s]\n",
            "11-785-s22-hw2p2-classification.zip   sample_data\n",
            "11-785-s22-hw2p2-verification.zip     train_subset\n",
            "classification\t\t\t      verification\n",
            "classification_sample_submission.csv  verification_sample_submission.csv\n",
            "drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvKned_mKs7_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as ttf\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKnENectKs8C"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, channels):\n",
        "\n",
        "        super().__init__()\n",
        "        \n",
        "        self.pointwise = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size = 3, padding = 1, bias = False),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels, channels, kernel_size = 3, padding = 1, bias = False),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pointwise(x)\n",
        "        out = x + out\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Downsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.downsample = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size = 2, stride = 2),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.downsample(x)\n",
        "        return out "
      ],
      "metadata": {
        "id": "EifAnGPyYloS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QquDmg9Ks8D"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, classes = 7000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.classes = classes\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size = 7, padding = 3, bias = False, stride = 2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.stages = [\n",
        "            [64, 3],\n",
        "            [128, 4],\n",
        "            [256, 6],\n",
        "            [512, 3],\n",
        "        ]\n",
        "\n",
        "        layers = self.make_layers()\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        final_channels = 512\n",
        "\n",
        "        self.cls_layer = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(final_channels, classes),\n",
        "        )\n",
        "\n",
        "    def make_layers(self):\n",
        "        layers = []\n",
        "\n",
        "        for idx, curr_stage in enumerate(self.stages):\n",
        "\n",
        "            in_channels, num_blocks = curr_stage\n",
        "            for __ in range(num_blocks):\n",
        "                layers.append(ResBlock(channels = in_channels))\n",
        "                \n",
        "            if idx != (len(self.stages)-1):\n",
        "                out_channels = self.stages[idx+1][0]\n",
        "                layers.append(Downsample(in_channels = in_channels, out_channels = out_channels))\n",
        "\n",
        "        return layers\n",
        "\n",
        "\n",
        "    def forward(self, x, return_feats = False):\n",
        "        out = self.stem(x)\n",
        "        out = self.layers(out)\n",
        "        if return_feats:\n",
        "            return out\n",
        "\n",
        "        out = self.cls_layer(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chelcRpFKs8G"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "lr = 0.1\n",
        "epochs = 60\n",
        "\n",
        "DATA_DIR = \"/content\"\n",
        "TRAIN_DIR = osp.join(DATA_DIR, \"classification/classification/train\")\n",
        "VAL_DIR = osp.join(DATA_DIR, \"classification/classification/dev\")\n",
        "TEST_DIR = osp.join(DATA_DIR, \"classification/classification/test\")\n",
        "\n",
        "\n",
        "train_transforms = ttf.Compose([\n",
        "                    ttf.RandomHorizontalFlip(),\n",
        "                    ttf.ColorJitter(),\n",
        "                    # ttf.RandomPerspective(0.3, 0.4),\n",
        "                    ttf.ToTensor(),\n",
        "                    ttf.Normalize((0.51301944, 0.40335497, 0.35214797), (0.30744416, 0.2702129 , 0.25891313)), \n",
        "                    ])\n",
        "\n",
        "val_transforms = ttf.Compose([ttf.ToTensor(),\n",
        "                  ttf.Normalize((0.51301944, 0.40335497, 0.35214797), (0.30744416, 0.2702129 , 0.25891313))])\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(VAL_DIR,\n",
        "                                               transform = val_transforms)\n",
        "train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR,\n",
        "                                                 transform = train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                          shuffle=True, drop_last=True, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        drop_last=True, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_parameters = 0\n",
        "for p in model.parameters():\n",
        "    num_trainable_parameters += p.numel()\n",
        "print(\"Number of Params: {}\".format(num_trainable_parameters))\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing = 0.25)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.95, weight_decay = 1.5e-4, nesterov = True)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU52sErh-kQY",
        "outputId": "db6a4b54-6a87-475d-8653-4c6d3b7bdf44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Params: 26940952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,epochs+1):\n",
        "    # Quality of life tip: leave=False and position=0 are needed to make tqdm usable in jupyter\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    model.train()\n",
        "    num_correct = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "\n",
        "        with torch.cuda.amp.autocast():     \n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "        total_loss += float(loss)\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * batch_size)),\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct=num_correct,\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        \n",
        "        \n",
        "        scaler.scale(loss).backward() \n",
        "        scaler.step(optimizer) \n",
        "        scaler.update() \n",
        "        scheduler.step()\n",
        "        batch_bar.update()\n",
        "\n",
        "        \n",
        "    batch_bar.close() \n",
        "    \n",
        "    print(\"Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "        epoch,\n",
        "        epochs,\n",
        "        100 * num_correct / (len(train_loader) * batch_size),\n",
        "        float(total_loss / len(train_loader)),\n",
        "        float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        model.eval()\n",
        "        batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "        num_correct = 0\n",
        "        for i, (x, y) in enumerate(val_loader):\n",
        "\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(x)\n",
        "\n",
        "            num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "            batch_bar.set_postfix(acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * batch_size)))\n",
        "\n",
        "            batch_bar.update()\n",
        "            \n",
        "        batch_bar.close()\n",
        "        print(\"Validation: {:.04f}%\".format(100 * num_correct / len(val_dataset)))\n",
        "    \n",
        "        ss = '/content/drive/MyDrive/HW2P2/models-res-res/convii'+str(epoch)\n",
        "        torch.save(model, ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV6KB2UshNkb",
        "outputId": "65a36a15-516b-4582-bb12-91627f0133bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60: Train Acc 0.0465%, Train Loss 8.7470, Learning Rate 0.0999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/60: Train Acc 0.6353%, Train Loss 8.1413, Learning Rate 0.0997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/60: Train Acc 4.5523%, Train Loss 7.3326, Learning Rate 0.0994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/60: Train Acc 15.2544%, Train Loss 6.5016, Learning Rate 0.0989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/60: Train Acc 30.9874%, Train Loss 5.7678, Learning Rate 0.0983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 27.9657%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/60: Train Acc 46.7534%, Train Loss 5.1763, Learning Rate 0.0976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/60: Train Acc 59.3936%, Train Loss 4.7347, Learning Rate 0.0967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/60: Train Acc 68.2149%, Train Loss 4.4223, Learning Rate 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/60: Train Acc 74.5858%, Train Loss 4.1894, Learning Rate 0.0946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/60: Train Acc 79.3341%, Train Loss 4.0152, Learning Rate 0.0933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 60.3000%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/60: Train Acc 82.6172%, Train Loss 3.8844, Learning Rate 0.0919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/60: Train Acc 85.4925%, Train Loss 3.7749, Learning Rate 0.0905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/60: Train Acc 87.7161%, Train Loss 3.6840, Learning Rate 0.0889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/60: Train Acc 89.6220%, Train Loss 3.6088, Learning Rate 0.0872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/60: Train Acc 91.0192%, Train Loss 3.5478, Learning Rate 0.0854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 67.4629%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/60: Train Acc 92.5009%, Train Loss 3.4915, Learning Rate 0.0835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/60: Train Acc 93.5382%, Train Loss 3.4457, Learning Rate 0.0815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/60: Train Acc 94.6057%, Train Loss 3.4023, Learning Rate 0.0794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/60: Train Acc 95.4685%, Train Loss 3.3644, Learning Rate 0.0772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/60: Train Acc 96.3220%, Train Loss 3.3302, Learning Rate 0.0750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 73.7914%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/60: Train Acc 96.9065%, Train Loss 3.3021, Learning Rate 0.0727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/60: Train Acc 97.3436%, Train Loss 3.2784, Learning Rate 0.0703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/60: Train Acc 97.8094%, Train Loss 3.2539, Learning Rate 0.0679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/60: Train Acc 98.1406%, Train Loss 3.2315, Learning Rate 0.0655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/60: Train Acc 98.5334%, Train Loss 3.2121, Learning Rate 0.0629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 78.6086%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/60: Train Acc 98.7745%, Train Loss 3.1926, Learning Rate 0.0604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/60: Train Acc 98.9218%, Train Loss 3.1775, Learning Rate 0.0578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/60: Train Acc 99.1551%, Train Loss 3.1600, Learning Rate 0.0552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/60: Train Acc 99.3304%, Train Loss 3.1434, Learning Rate 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/60: Train Acc 99.4362%, Train Loss 3.1292, Learning Rate 0.0500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 79.9343%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/60: Train Acc 99.5686%, Train Loss 3.1135, Learning Rate 0.0474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/60: Train Acc 99.6294%, Train Loss 3.0998, Learning Rate 0.0448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/60: Train Acc 99.7067%, Train Loss 3.0863, Learning Rate 0.0422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/60: Train Acc 99.7918%, Train Loss 3.0708, Learning Rate 0.0396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/60: Train Acc 99.8505%, Train Loss 3.0577, Learning Rate 0.0371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 81.3857%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/60: Train Acc 99.8877%, Train Loss 3.0446, Learning Rate 0.0345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/60: Train Acc 99.9113%, Train Loss 3.0310, Learning Rate 0.0321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/60: Train Acc 99.9356%, Train Loss 3.0188, Learning Rate 0.0297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/60: Train Acc 99.9549%, Train Loss 3.0084, Learning Rate 0.0273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/60: Train Acc 99.9649%, Train Loss 2.9965, Learning Rate 0.0250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.3514%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/60: Train Acc 99.9800%, Train Loss 2.9850, Learning Rate 0.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/60: Train Acc 99.9921%, Train Loss 2.9752, Learning Rate 0.0206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/60: Train Acc 99.9907%, Train Loss 2.9652, Learning Rate 0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/60: Train Acc 99.9893%, Train Loss 2.9564, Learning Rate 0.0165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/60: Train Acc 99.9943%, Train Loss 2.9481, Learning Rate 0.0146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 86.0229%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/60: Train Acc 99.9957%, Train Loss 2.9410, Learning Rate 0.0128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/60: Train Acc 99.9971%, Train Loss 2.9349, Learning Rate 0.0111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/60: Train Acc 99.9979%, Train Loss 2.9298, Learning Rate 0.0095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/60: Train Acc 99.9971%, Train Loss 2.9246, Learning Rate 0.0081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/60: Train Acc 99.9979%, Train Loss 2.9206, Learning Rate 0.0067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 86.9543%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/60: Train Acc 99.9986%, Train Loss 2.9170, Learning Rate 0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/60: Train Acc 99.9993%, Train Loss 2.9140, Learning Rate 0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/60: Train Acc 100.0000%, Train Loss 2.9116, Learning Rate 0.0033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/60: Train Acc 99.9993%, Train Loss 2.9097, Learning Rate 0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/60: Train Acc 99.9993%, Train Loss 2.9079, Learning Rate 0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 87.2857%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/60: Train Acc 99.9993%, Train Loss 2.9069, Learning Rate 0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/60: Train Acc 100.0000%, Train Loss 2.9058, Learning Rate 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/60: Train Acc 100.0000%, Train Loss 2.9053, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/60: Train Acc 100.0000%, Train Loss 2.9048, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/60: Train Acc 100.0000%, Train Loss 2.9045, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 87.2857%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationTestSet(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms):\n",
        "        self.data_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        self.img_paths = list(map(lambda fname: osp.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.transforms(Image.open(self.img_paths[idx]))"
      ],
      "metadata": {
        "id": "fa5_MgEvGipI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = ClassificationTestSet(TEST_DIR, val_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False,\n",
        "                         drop_last=False, num_workers=1)"
      ],
      "metadata": {
        "id": "lbe9TQmVGvdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(test_loader), dynamic_ncols=True, position=0, leave=False, desc='Test')\n",
        "\n",
        "    res = np.array([])\n",
        "    for i, (x) in enumerate(test_loader):\n",
        "        input_image = x.cuda()\n",
        "        output = model(input_image)\n",
        "        prediction = torch.argmax(output, axis=1).to('cpu')\n",
        "        res = np.append(res, prediction.numpy())\n",
        "        batch_bar.update()\n",
        "        \n",
        "    batch_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HvDRD9wGx9F",
        "outputId": "1c63ecd8-f435-44d8-f65e-558ce211e1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = res.astype(int)\n",
        "with open(\"classification_early_submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(test_dataset)):\n",
        "        f.write(\"{},{}\\n\".format(str(i).zfill(6) + \".jpg\", res[i]))"
      ],
      "metadata": {
        "id": "g53sH0wpGz-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions submit -c 11-785-s22-hw2p2-classification -f classification_early_submission.csv -m \"NA\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trRizZf6G3fa",
        "outputId": "d7e93b69-6c6a-4b63-a9a7-586968606b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 541k/541k [00:05<00:00, 94.6kB/s]\n",
            "Successfully submitted to Face Recognition"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VerificationDataset(Dataset):\n",
        "    def __init__(self, data_dir, transforms):\n",
        "        self.data_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # This one-liner basically generates a sorted list of full paths to each image in data_dir\n",
        "        self.img_paths = list(map(lambda fname: osp.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # We return the image, as well as the path to that image (relative path)\n",
        "        return self.transforms(Image.open(self.img_paths[idx])), osp.relpath(self.img_paths[idx], self.data_dir)"
      ],
      "metadata": {
        "id": "WEF39Sbb6f8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JSE8yaj-q4",
        "outputId": "a32525ac-0059-4ce3-ad14-ac12bcc30592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.51301944, 0.40335497, 0.35214797), std=(0.30744416, 0.2702129, 0.25891313))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_veri_dataset = VerificationDataset(osp.join(DATA_DIR, \"verification/verification/dev\"), val_transforms)\n",
        "val_ver_loader = torch.utils.data.DataLoader(val_veri_dataset, batch_size=batch_size, \n",
        "                                             shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "_KIk1Hzz6hbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "feats_dict = dict()\n",
        "for batch_idx, (imgs, path_names) in tqdm(enumerate(val_ver_loader), total=len(val_ver_loader), position=0, leave=False):\n",
        "    imgs = imgs.cuda()\n",
        "    with torch.no_grad():\n",
        "        # Note that we return the feats here, not the final outputs\n",
        "        # Feel free to try the final outputs too!\n",
        "        feats = model(imgs, return_feats = True)\n",
        "        for img_name, embedding in zip(path_names, feats):\n",
        "            feats_dict['dev/'+img_name] = embedding\n",
        "    # TODO: Now we have features and the image path names. What to do with them?\n",
        "    # Hint: use the feats_dict somehow."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_olagGX6i5n",
        "outputId": "2f24be3a-7ed7-463b-aa49-fd6c9637b9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use cosine similarity between feature embeddings.\n",
        "# TODO: Find the relevant function in pytorch and read its documentation.\n",
        "similarity_metric = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "val_veri_csv = osp.join(DATA_DIR, \"verification/verification/verification_dev.csv\")\n",
        "\n",
        "\n",
        "# Now, loop through the csv and compare each pair, getting the similarity between them\n",
        "pred_similarities = []\n",
        "gt_similarities = []\n",
        "for line in tqdm(open(val_veri_csv).read().splitlines()[1:], position=0, leave=False): # skip header\n",
        "    img_path1, img_path2, gt = line.split(\",\")\n",
        "\n",
        "    similarity = similarity_metric(feats_dict[img_path1],feats_dict[img_path2])\n",
        "    pred_similarities.append(similarity.cpu().numpy())\n",
        "    gt_similarities.append(int(gt))\n",
        "\n",
        "pred_similarities = np.array(pred_similarities)\n",
        "gt_similarities = np.array(gt_similarities)\n",
        "# pred_similarities_avg = np.mean(pred_similarities, axis = (1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQIGeZQA6kMD",
        "outputId": "b95dfda5-0043-4be8-f1fd-fcde7ae9d23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_similarities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7QTEQsasnsb",
        "outputId": "0b10304e-9af5-4618-961f-fdbd3a6d14e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.82377017,  0.5729863 ,  0.42320836, ...,  0.5230511 ,\n",
              "          0.58104306,  0.8321384 ],\n",
              "        [ 0.3145008 ,  0.27459118,  0.3023045 , ...,  0.24750963,\n",
              "          0.13598429,  0.16847019],\n",
              "        [ 0.2768411 ,  0.26482818,  0.35657415, ...,  0.3624979 ,\n",
              "          0.22425668,  0.10787322],\n",
              "        ...,\n",
              "        [ 0.44831637,  0.43629894,  0.5518107 , ...,  0.52631074,\n",
              "          0.39577594,  0.29823503],\n",
              "        [ 0.57992506,  0.35480937,  0.46189806, ...,  0.43099782,\n",
              "          0.34787092,  0.40202567],\n",
              "        [ 0.87842506,  0.7209258 ,  0.6057954 , ...,  0.5370739 ,\n",
              "          0.6628217 ,  0.8686696 ]],\n",
              "\n",
              "       [[ 0.9188603 ,  0.60921067,  0.30519232, ...,  0.2804889 ,\n",
              "          0.37876323,  0.65714866],\n",
              "        [ 0.5792971 ,  0.06475962,  0.08167127, ...,  0.07043648,\n",
              "          0.14538717,  0.20882432],\n",
              "        [ 0.4572583 ,  0.0798768 ,  0.09816156, ...,  0.01824662,\n",
              "          0.04520112,  0.08696   ],\n",
              "        ...,\n",
              "        [ 0.5709415 ,  0.13493557,  0.15733431, ...,  0.05764989,\n",
              "          0.05501661,  0.02261589],\n",
              "        [ 0.5615213 ,  0.14611208,  0.13154592, ...,  0.04398612,\n",
              "          0.03952157,  0.08460052],\n",
              "        [ 0.8183617 ,  0.6264666 ,  0.37664518, ...,  0.23924364,\n",
              "          0.43347403,  0.705366  ]],\n",
              "\n",
              "       [[ 0.6644684 ,  0.36092898,  0.18312572, ...,  0.17814761,\n",
              "          0.20970537,  0.42396304],\n",
              "        [ 0.3562568 ,  0.18207817,  0.07205838, ...,  0.03950391,\n",
              "          0.11499984,  0.18816884],\n",
              "        [ 0.35633472,  0.13351858,  0.09409984, ...,  0.02172676,\n",
              "          0.06285243,  0.10241329],\n",
              "        ...,\n",
              "        [ 0.20802109,  0.08232292,  0.06571002, ...,  0.06612128,\n",
              "          0.07965183,  0.07116017],\n",
              "        [ 0.16427535,  0.07122082,  0.02648445, ...,  0.03945706,\n",
              "          0.02439623,  0.05166881],\n",
              "        [ 0.5840554 ,  0.395991  ,  0.23769039, ...,  0.2714328 ,\n",
              "          0.32272208,  0.5304167 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.79262984,  0.302715  ,  0.19182998, ...,  0.20155169,\n",
              "          0.29464155,  0.6771716 ],\n",
              "        [ 0.1809532 ,  0.04310982,  0.09671809, ...,  0.07353733,\n",
              "         -0.0122196 ,  0.03069758],\n",
              "        [ 0.13622731,  0.14016858,  0.13918039, ...,  0.13056067,\n",
              "          0.08484628,  0.09908701],\n",
              "        ...,\n",
              "        [ 0.20903851,  0.1141464 ,  0.09311005, ...,  0.05735212,\n",
              "          0.05477731,  0.23018725],\n",
              "        [ 0.21061666,  0.08005432,  0.08334754, ...,  0.04640148,\n",
              "          0.1031547 ,  0.34877974],\n",
              "        [ 0.67051435,  0.40411505,  0.2787859 , ...,  0.32006547,\n",
              "          0.5664352 ,  0.8379092 ]],\n",
              "\n",
              "       [[ 0.7547877 ,  0.49529493,  0.4148548 , ...,  0.44078204,\n",
              "          0.50363094,  0.71801096],\n",
              "        [ 0.17150678,  0.15073746,  0.3222818 , ...,  0.49609104,\n",
              "          0.49124467,  0.3627453 ],\n",
              "        [ 0.13417313,  0.27964088,  0.46839502, ...,  0.52306557,\n",
              "          0.4447784 ,  0.3377717 ],\n",
              "        ...,\n",
              "        [ 0.36237496,  0.35260063,  0.51929194, ...,  0.42545995,\n",
              "          0.17647074,  0.06468197],\n",
              "        [ 0.574941  ,  0.4626594 ,  0.62262255, ...,  0.47169107,\n",
              "          0.19318143, -0.03010784],\n",
              "        [ 0.90535814,  0.69729906,  0.5988952 , ...,  0.45943484,\n",
              "          0.36112007,  0.48594508]],\n",
              "\n",
              "       [[ 0.7208039 ,  0.47246933,  0.52163154, ...,  0.52927434,\n",
              "          0.70643187,  0.9278306 ],\n",
              "        [ 0.28189173,  0.30950546,  0.44569203, ...,  0.5055241 ,\n",
              "          0.5420348 ,  0.67417103],\n",
              "        [ 0.3735517 ,  0.41317615,  0.537381  , ...,  0.67237234,\n",
              "          0.6725887 ,  0.5772152 ],\n",
              "        ...,\n",
              "        [ 0.4650638 ,  0.63073397,  0.7588512 , ...,  0.7699996 ,\n",
              "          0.6803943 ,  0.511827  ],\n",
              "        [ 0.59852993,  0.61557627,  0.71617216, ...,  0.7136678 ,\n",
              "          0.5355101 ,  0.45534548],\n",
              "        [ 0.86210215,  0.63977015,  0.63244   , ...,  0.7138906 ,\n",
              "          0.65616006,  0.7498014 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_similarities.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX6CiYYYiKYd",
        "outputId": "a0b47cfe-8d9f-49f9-e2c7-ab1c7e71e943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166800,)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_similarities_avg = np.mean(pred_similarities, axis = (1,2))\n",
        "print(\"AUC:\", roc_auc_score(gt_similarities, pred_similarities_avg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajm7aMea6GtF",
        "outputId": "23fe4aea-e800-4f3f-cba2-d6d0095de464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9045100957770504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_veri_dataset = VerificationDataset(osp.join(DATA_DIR, \"verification/verification/test\"), val_transforms)\n",
        "test_ver_loader = torch.utils.data.DataLoader(test_veri_dataset, batch_size=batch_size, \n",
        "                                              shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "8rFOZfLk6onr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "feats_dict = dict()\n",
        "for batch_idx, (imgs, path_names) in tqdm(enumerate(test_ver_loader), total=len(test_ver_loader), position=0, leave=False):\n",
        "    imgs = imgs.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Note that we return the feats here, not the final outputs\n",
        "        # Feel free to try to final outputs too!\n",
        "        feats = model(imgs) \n",
        "        for img_name, embedding in zip(path_names, feats):\n",
        "            feats_dict['test/'+img_name] = embedding\n",
        "    \n",
        "    # TODO: Now we have features and the image path names. What to do with them?\n",
        "    # Hint: use the feats_dict somehow."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCPHwvta6pE0",
        "outputId": "f484447e-7608-4389-820d-9af3ccb72651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use cosine similarity between feature embeddings.\n",
        "# TODO: Find the relevant function in pytorch and read its documentation.\n",
        "# similarity_metric = \n",
        "val_veri_csv = osp.join(DATA_DIR, \"verification/verification/verification_test.csv\")\n",
        "\n",
        "\n",
        "# Now, loop through the csv and compare each pair, getting the similarity between them\n",
        "pred_similarities = []\n",
        "for line in tqdm(open(val_veri_csv).read().splitlines()[1:], position=0, leave=False): # skip header\n",
        "    img_path1, img_path2 = line.split(\",\")\n",
        "\n",
        "    similarity = similarity_metric(feats_dict[img_path1],feats_dict[img_path2])\n",
        "    pred_similarities.append(similarity.cpu().numpy())\n",
        "    \n",
        "pred_similarities = np.array(pred_similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEOlcrNM6qeU",
        "outputId": "5e650c16-0d98-404b-e5c7-42109a95c267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"verification_early_submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,match\\n\")\n",
        "    for i in range(len(pred_similarities)):\n",
        "        f.write(\"{},{}\\n\".format(i, pred_similarities[i]))"
      ],
      "metadata": {
        "id": "jGpOGBMQ6stQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions submit -c 11-785-s22-hw2p2-verification -f verification_early_submission.csv -m \"NA\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq6xCqah6u83",
        "outputId": "c3ed45be-cf67-4c72-a1b8-7f35f62a7275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 16.9M/16.9M [00:00<00:00, 45.9MB/s]\n",
            "Successfully submitted to Face Verification"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H6xf8pwC_nqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "3325ce98b0e3092794368775f7268d48d8b7f22d032187877226117cae8da226"
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 ('mambaforge')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Face Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}